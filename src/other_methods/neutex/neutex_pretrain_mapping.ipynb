{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1356deb-21f1-4c1a-b968-04d44148f41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pytorch3d.loss import chamfer_distance\n",
    "import trimesh\n",
    "import os\n",
    "import pyvista as pv\n",
    "pv.set_jupyter_backend(\"ipyvtklink\")\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from neutex.neutex import make_neutex_for_pretraining\n",
    "from utils import to_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "193289f8-964b-4635-a168-e8b030d56c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mesh_path = \"../human_and_cat/cat_rescaled_rotated/12221_Cat_v1_l3.obj\"\n",
    "mesh_path = \"../human_and_cat/human/RUST_3d_Low1.obj\"\n",
    "\n",
    "out_dir = \"pretrained/cat_rescaled_rotated_pretrained_neutex_mapping.pt\"\n",
    "\n",
    "device = \"cuda\"\n",
    "\n",
    "mesh = trimesh.load(mesh_path)\n",
    "mesh_vertices = torch.from_numpy(mesh.vertices).to(device=device, dtype=torch.float32)\n",
    "\n",
    "iterations = 200000\n",
    "lr = 1e-4\n",
    "\n",
    "print_every_iter = 500\n",
    "\n",
    "model = make_neutex_for_pretraining()\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "loss_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2b9b8ab-9c94-4f70-87cb-6191a7f91775",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration       1/ 200000  Loss: 2.3564696311950684   Chamfer Loss: 0.2002539485692978    Cycle Loss: 2.1562156677246094\n",
      "Iteration     501/ 200000  Loss: 0.001901326235383749   Chamfer Loss: 0.0016272645443677902    Cycle Loss: 0.0002740616910159588\n",
      "Iteration    1001/ 200000  Loss: 0.001260992605239153   Chamfer Loss: 0.001127648283727467    Cycle Loss: 0.00013334437971934676\n",
      "Iteration    1501/ 200000  Loss: 0.0009812181815505028   Chamfer Loss: 0.0008761473000049591    Cycle Loss: 0.00010507083788979799\n",
      "Iteration    2001/ 200000  Loss: 0.0007864492363296449   Chamfer Loss: 0.0007119540241546929    Cycle Loss: 7.449519034707919e-05\n",
      "Iteration    2501/ 200000  Loss: 0.0006565519142895937   Chamfer Loss: 0.0005744797526858747    Cycle Loss: 8.207213977584615e-05\n",
      "Iteration    3001/ 200000  Loss: 0.0005779577768407762   Chamfer Loss: 0.0005062114796601236    Cycle Loss: 7.174631900852546e-05\n",
      "Iteration    3501/ 200000  Loss: 0.0005152731901034713   Chamfer Loss: 0.00046285928692668676    Cycle Loss: 5.241391409072094e-05\n",
      "Iteration    4001/ 200000  Loss: 0.0005381499067880213   Chamfer Loss: 0.00042059842962771654    Cycle Loss: 0.00011755145533243194\n",
      "Iteration    4501/ 200000  Loss: 0.0004325842601247132   Chamfer Loss: 0.0003882425371557474    Cycle Loss: 4.4341726606944576e-05\n",
      "Iteration    5001/ 200000  Loss: 0.00044510597945190966   Chamfer Loss: 0.00036068190820515156    Cycle Loss: 8.44240712467581e-05\n",
      "Iteration    5501/ 200000  Loss: 0.00038039093487896025   Chamfer Loss: 0.00034040294121950865    Cycle Loss: 3.998799729743041e-05\n",
      "Iteration    6001/ 200000  Loss: 0.00039512934745289385   Chamfer Loss: 0.0003260019875597209    Cycle Loss: 6.912735261721537e-05\n",
      "Iteration    6501/ 200000  Loss: 0.00036057239049114287   Chamfer Loss: 0.0003078891313634813    Cycle Loss: 5.268325548968278e-05\n",
      "Iteration    7001/ 200000  Loss: 0.0003471779346000403   Chamfer Loss: 0.00030268204864114523    Cycle Loss: 4.449588595889509e-05\n",
      "Iteration    7501/ 200000  Loss: 0.00039677455788478255   Chamfer Loss: 0.00028568171546794474    Cycle Loss: 0.00011109284969279543\n",
      "Iteration    8001/ 200000  Loss: 0.000319566490361467   Chamfer Loss: 0.00027556571876630187    Cycle Loss: 4.400076431920752e-05\n",
      "Iteration    8501/ 200000  Loss: 0.0003274220216553658   Chamfer Loss: 0.00026874319883063436    Cycle Loss: 5.8678826462710276e-05\n",
      "Iteration    9001/ 200000  Loss: 0.00028165505500510335   Chamfer Loss: 0.0002550331118982285    Cycle Loss: 2.6621930373949e-05\n",
      "Iteration    9501/ 200000  Loss: 0.0002804735559038818   Chamfer Loss: 0.00024647655664011836    Cycle Loss: 3.39969847118482e-05\n",
      "Iteration   10001/ 200000  Loss: 0.0002959332487080246   Chamfer Loss: 0.00024036293325480074    Cycle Loss: 5.557030453928746e-05\n",
      "Iteration   10501/ 200000  Loss: 0.00026290869573131204   Chamfer Loss: 0.0002306605747435242    Cycle Loss: 3.224813553970307e-05\n",
      "Iteration   11001/ 200000  Loss: 0.00025679392274469137   Chamfer Loss: 0.00022337115660775453    Cycle Loss: 3.3422751585021615e-05\n",
      "Iteration   11501/ 200000  Loss: 0.00024169533571694046   Chamfer Loss: 0.00021711426961701363    Cycle Loss: 2.458106609992683e-05\n",
      "Iteration   12001/ 200000  Loss: 0.00026966858422383666   Chamfer Loss: 0.0002180890878662467    Cycle Loss: 5.157951090950519e-05\n",
      "Iteration   12501/ 200000  Loss: 0.00023126084124669433   Chamfer Loss: 0.00020546530140563846    Cycle Loss: 2.5795536203077063e-05\n",
      "Iteration   13001/ 200000  Loss: 0.0002905722358264029   Chamfer Loss: 0.00020360466442070901    Cycle Loss: 8.696757140569389e-05\n",
      "Iteration   13501/ 200000  Loss: 0.00024689652491360903   Chamfer Loss: 0.0001965782867046073    Cycle Loss: 5.0318230933044106e-05\n",
      "Iteration   14001/ 200000  Loss: 0.00022935519518796355   Chamfer Loss: 0.00018935375555884093    Cycle Loss: 4.0001439629122615e-05\n",
      "Iteration   14501/ 200000  Loss: 0.00021983221813570708   Chamfer Loss: 0.0001844238577177748    Cycle Loss: 3.540836041793227e-05\n",
      "Iteration   15001/ 200000  Loss: 0.00020267027139198035   Chamfer Loss: 0.00018393532081972808    Cycle Loss: 1.8734952391241677e-05\n",
      "Iteration   15501/ 200000  Loss: 0.00023127398162614554   Chamfer Loss: 0.00018010125495493412    Cycle Loss: 5.117272667121142e-05\n",
      "Iteration   16001/ 200000  Loss: 0.00025112583534792066   Chamfer Loss: 0.00017763880896382034    Cycle Loss: 7.348701183218509e-05\n",
      "Iteration   16501/ 200000  Loss: 0.00022839696612209082   Chamfer Loss: 0.0001696965773589909    Cycle Loss: 5.870038876309991e-05\n",
      "Iteration   17001/ 200000  Loss: 0.0002418263757135719   Chamfer Loss: 0.00016481216880492866    Cycle Loss: 7.701421418460086e-05\n",
      "Iteration   17501/ 200000  Loss: 0.00024412386119365692   Chamfer Loss: 0.00016407991643063724    Cycle Loss: 8.004394476301968e-05\n",
      "Iteration   18001/ 200000  Loss: 0.00019066297682002187   Chamfer Loss: 0.0001614164502825588    Cycle Loss: 2.9246533813420683e-05\n",
      "Iteration   18501/ 200000  Loss: 0.00018238689517602324   Chamfer Loss: 0.00016141340893227607    Cycle Loss: 2.0973480786778964e-05\n",
      "Iteration   19001/ 200000  Loss: 0.0002343378437217325   Chamfer Loss: 0.0001590877800481394    Cycle Loss: 7.52500636735931e-05\n",
      "Iteration   19501/ 200000  Loss: 0.00017339608166366816   Chamfer Loss: 0.00015256770711857826    Cycle Loss: 2.0828381821047515e-05\n",
      "Iteration   20001/ 200000  Loss: 0.00018516283307690173   Chamfer Loss: 0.00014849714352749288    Cycle Loss: 3.6665685911430046e-05\n",
      "Iteration   20501/ 200000  Loss: 0.00017662427853792906   Chamfer Loss: 0.00014663831098005176    Cycle Loss: 2.9985960281919688e-05\n",
      "Iteration   21001/ 200000  Loss: 0.0003732857876457274   Chamfer Loss: 0.00015251697914209217    Cycle Loss: 0.00022076880850363523\n",
      "Iteration   21501/ 200000  Loss: 0.00016531531582586467   Chamfer Loss: 0.00014312854909803718    Cycle Loss: 2.2186759451869875e-05\n",
      "Iteration   22001/ 200000  Loss: 0.00016106083057820797   Chamfer Loss: 0.00014098201063461602    Cycle Loss: 2.0078812667634338e-05\n",
      "Iteration   22501/ 200000  Loss: 0.0001695409300737083   Chamfer Loss: 0.00014049444871488959    Cycle Loss: 2.9046483177808113e-05\n",
      "Iteration   23001/ 200000  Loss: 0.00029887654818594456   Chamfer Loss: 0.00014332997670862824    Cycle Loss: 0.00015554657147731632\n",
      "Iteration   23501/ 200000  Loss: 0.0002022102999035269   Chamfer Loss: 0.00013303478772286326    Cycle Loss: 6.917551945662126e-05\n",
      "Iteration   24001/ 200000  Loss: 0.0002055050863418728   Chamfer Loss: 0.00013496127212420106    Cycle Loss: 7.054381421767175e-05\n",
      "Iteration   24501/ 200000  Loss: 0.0001709919306449592   Chamfer Loss: 0.00013193585618864745    Cycle Loss: 3.9056070818332955e-05\n",
      "Iteration   25001/ 200000  Loss: 0.0001623935968382284   Chamfer Loss: 0.00013386932550929487    Cycle Loss: 2.8524269509944133e-05\n",
      "Iteration   25501/ 200000  Loss: 0.00014361765352077782   Chamfer Loss: 0.00012751454778481275    Cycle Loss: 1.610310391697567e-05\n",
      "Iteration   26001/ 200000  Loss: 0.00013786402996629477   Chamfer Loss: 0.00012674178287852556    Cycle Loss: 1.1122245268779807e-05\n",
      "Iteration   26501/ 200000  Loss: 0.00015692191664129496   Chamfer Loss: 0.00013080891221761703    Cycle Loss: 2.6113000785699114e-05\n",
      "Iteration   27001/ 200000  Loss: 0.00015073275426402688   Chamfer Loss: 0.00012426261673681438    Cycle Loss: 2.6470144803170115e-05\n",
      "Iteration   27501/ 200000  Loss: 0.00014903178089298308   Chamfer Loss: 0.0001232931244885549    Cycle Loss: 2.5738658223417588e-05\n",
      "Iteration   28001/ 200000  Loss: 0.00013076511095277965   Chamfer Loss: 0.00011939376418013126    Cycle Loss: 1.1371347682143096e-05\n",
      "Iteration   28501/ 200000  Loss: 0.00014411186566576362   Chamfer Loss: 0.00012185199011582881    Cycle Loss: 2.225987918791361e-05\n",
      "Iteration   29001/ 200000  Loss: 0.00013031855633016676   Chamfer Loss: 0.00011767871183110401    Cycle Loss: 1.263985086552566e-05\n",
      "Iteration   29501/ 200000  Loss: 0.0001470088609494269   Chamfer Loss: 0.00011713787534972653    Cycle Loss: 2.9870991056668572e-05\n",
      "Iteration   30001/ 200000  Loss: 0.00023745096405036747   Chamfer Loss: 0.00011698737216647714    Cycle Loss: 0.00012046359915984794\n",
      "Iteration   30501/ 200000  Loss: 0.00012355051876511425   Chamfer Loss: 0.00011345519305905327    Cycle Loss: 1.009532752505038e-05\n",
      "Iteration   31001/ 200000  Loss: 0.0001464359520468861   Chamfer Loss: 0.00011368888954166323    Cycle Loss: 3.274705886724405e-05\n",
      "Iteration   31501/ 200000  Loss: 0.0001336685090791434   Chamfer Loss: 0.00011334094597259536    Cycle Loss: 2.0327566744526848e-05\n",
      "Iteration   32001/ 200000  Loss: 0.00012516822607722133   Chamfer Loss: 0.0001114484402933158    Cycle Loss: 1.3719792150368448e-05\n",
      "Iteration   32501/ 200000  Loss: 0.00015303041436709464   Chamfer Loss: 0.00011141310096718371    Cycle Loss: 4.161730612395331e-05\n",
      "Iteration   33001/ 200000  Loss: 0.00013121659867465496   Chamfer Loss: 0.00011015977361239493    Cycle Loss: 2.1056825062260032e-05\n",
      "Iteration   33501/ 200000  Loss: 0.00012182516366010532   Chamfer Loss: 0.00011040070239687338    Cycle Loss: 1.1424462172726635e-05\n",
      "Iteration   34001/ 200000  Loss: 0.0001337275025434792   Chamfer Loss: 0.00011085715959779918    Cycle Loss: 2.2870344764669426e-05\n",
      "Iteration   34501/ 200000  Loss: 0.0001455928140785545   Chamfer Loss: 0.00010558150825090706    Cycle Loss: 4.001131310360506e-05\n",
      "Iteration   35001/ 200000  Loss: 0.0001446856331313029   Chamfer Loss: 0.00010603053669910878    Cycle Loss: 3.865509279421531e-05\n",
      "Iteration   35501/ 200000  Loss: 0.00014584219024982303   Chamfer Loss: 0.00010292068327544257    Cycle Loss: 4.292150697438046e-05\n",
      "Iteration   36001/ 200000  Loss: 0.00012466713087633252   Chamfer Loss: 0.00010244175064144656    Cycle Loss: 2.2225383872864768e-05\n",
      "Iteration   36501/ 200000  Loss: 0.00012418694677762687   Chamfer Loss: 0.00010681565618142486    Cycle Loss: 1.7371296053170227e-05\n",
      "Iteration   37001/ 200000  Loss: 0.00013671180931851268   Chamfer Loss: 0.000104185935924761    Cycle Loss: 3.2525880669709295e-05\n",
      "Iteration   37501/ 200000  Loss: 0.00012765562860295177   Chamfer Loss: 0.0001035425957525149    Cycle Loss: 2.4113027393468656e-05\n",
      "Iteration   38001/ 200000  Loss: 0.00012148198584327474   Chamfer Loss: 9.991780098062009e-05    Cycle Loss: 2.1564184862654656e-05\n",
      "Iteration   38501/ 200000  Loss: 0.00013713620137423277   Chamfer Loss: 9.875603427644819e-05    Cycle Loss: 3.838016709778458e-05\n",
      "Iteration   39001/ 200000  Loss: 0.00013422303891275078   Chamfer Loss: 9.934414265444502e-05    Cycle Loss: 3.4878899896284565e-05\n",
      "Iteration   39501/ 200000  Loss: 0.00011554188677109778   Chamfer Loss: 9.68565364019014e-05    Cycle Loss: 1.8685346731217578e-05\n",
      "Iteration   40001/ 200000  Loss: 0.00014372677833307534   Chamfer Loss: 9.667913400335237e-05    Cycle Loss: 4.7047640691744164e-05\n",
      "Iteration   40501/ 200000  Loss: 0.00011934117355849594   Chamfer Loss: 9.537734877085313e-05    Cycle Loss: 2.396382660663221e-05\n",
      "Iteration   41001/ 200000  Loss: 0.00015748929581604898   Chamfer Loss: 9.807999595068395e-05    Cycle Loss: 5.940929622738622e-05\n",
      "Iteration   41501/ 200000  Loss: 0.0001095582265406847   Chamfer Loss: 9.462027810513973e-05    Cycle Loss: 1.493794479756616e-05\n",
      "Iteration   42001/ 200000  Loss: 0.0001388939272146672   Chamfer Loss: 9.393668005941436e-05    Cycle Loss: 4.4957247155252844e-05\n",
      "Iteration   42501/ 200000  Loss: 0.00010862808994716033   Chamfer Loss: 9.585756924934685e-05    Cycle Loss: 1.2770518878824078e-05\n",
      "Iteration   43001/ 200000  Loss: 0.0001370250975014642   Chamfer Loss: 9.478392894379795e-05    Cycle Loss: 4.224117219564505e-05\n",
      "Iteration   43501/ 200000  Loss: 0.00010579775698715821   Chamfer Loss: 9.01782768778503e-05    Cycle Loss: 1.561948192829732e-05\n",
      "Iteration   44001/ 200000  Loss: 0.00010537871276028454   Chamfer Loss: 9.533833508612588e-05    Cycle Loss: 1.0040375855169259e-05\n",
      "Iteration   44501/ 200000  Loss: 0.0001087692508008331   Chamfer Loss: 8.959195838542655e-05    Cycle Loss: 1.9177296053385362e-05\n",
      "Iteration   45001/ 200000  Loss: 0.00011752245336538181   Chamfer Loss: 9.212567238137126e-05    Cycle Loss: 2.539678280299995e-05\n",
      "Iteration   45501/ 200000  Loss: 0.0001124658519984223   Chamfer Loss: 8.935246296459809e-05    Cycle Loss: 2.3113389033824205e-05\n",
      "Iteration   46001/ 200000  Loss: 0.00013298937119543552   Chamfer Loss: 9.239405335392803e-05    Cycle Loss: 4.05953214794863e-05\n",
      "Iteration   46501/ 200000  Loss: 0.00010571072925813496   Chamfer Loss: 9.060554293682799e-05    Cycle Loss: 1.5105185411812272e-05\n",
      "Iteration   47001/ 200000  Loss: 0.00010272662620991468   Chamfer Loss: 8.858182991389185e-05    Cycle Loss: 1.414479538652813e-05\n",
      "Iteration   47501/ 200000  Loss: 0.00012326442811172456   Chamfer Loss: 8.799452189123258e-05    Cycle Loss: 3.5269906220491976e-05\n",
      "Iteration   48001/ 200000  Loss: 0.00010141212987946346   Chamfer Loss: 9.055539703695104e-05    Cycle Loss: 1.0856735570996534e-05\n",
      "Iteration   48501/ 200000  Loss: 0.00011433639883762226   Chamfer Loss: 8.936153608374298e-05    Cycle Loss: 2.497486275387928e-05\n",
      "Iteration   49001/ 200000  Loss: 0.00011027290020138025   Chamfer Loss: 8.942889689933509e-05    Cycle Loss: 2.0844001483055763e-05\n",
      "Iteration   49501/ 200000  Loss: 9.978019807022065e-05   Chamfer Loss: 8.697339217178524e-05    Cycle Loss: 1.2806805898435414e-05\n",
      "Iteration   50001/ 200000  Loss: 9.528145892545581e-05   Chamfer Loss: 8.674766286276281e-05    Cycle Loss: 8.533796972187702e-06\n",
      "Iteration   50501/ 200000  Loss: 0.00013998198846820742   Chamfer Loss: 8.874169725459069e-05    Cycle Loss: 5.124029121361673e-05\n",
      "Iteration   51001/ 200000  Loss: 9.968166705220938e-05   Chamfer Loss: 8.422390965279192e-05    Cycle Loss: 1.5457755580428056e-05\n",
      "Iteration   51501/ 200000  Loss: 0.0001030500716296956   Chamfer Loss: 8.709135727258399e-05    Cycle Loss: 1.5958714357111603e-05\n",
      "Iteration   52001/ 200000  Loss: 0.00012724430416710675   Chamfer Loss: 8.62012748257257e-05    Cycle Loss: 4.104302934138104e-05\n",
      "Iteration   52501/ 200000  Loss: 0.00010786909115267918   Chamfer Loss: 8.441541285719723e-05    Cycle Loss: 2.3453680114471354e-05\n",
      "Iteration   53001/ 200000  Loss: 0.00023426717962138355   Chamfer Loss: 9.02858009794727e-05    Cycle Loss: 0.00014398137864191085\n",
      "Iteration   53501/ 200000  Loss: 0.0001197087112814188   Chamfer Loss: 8.602565503679216e-05    Cycle Loss: 3.368305624462664e-05\n",
      "Iteration   54001/ 200000  Loss: 0.00011409004218876362   Chamfer Loss: 8.164309110725299e-05    Cycle Loss: 3.244695471948944e-05\n",
      "Iteration   54501/ 200000  Loss: 0.00011373826419003308   Chamfer Loss: 8.433740003965795e-05    Cycle Loss: 2.9400867788353935e-05\n",
      "Iteration   55001/ 200000  Loss: 0.0001531724992673844   Chamfer Loss: 8.447802974842489e-05    Cycle Loss: 6.869447679491714e-05\n",
      "Iteration   55501/ 200000  Loss: 0.00015243125380948186   Chamfer Loss: 8.455965871689841e-05    Cycle Loss: 6.787159509258345e-05\n",
      "Iteration   56001/ 200000  Loss: 9.234868048224598e-05   Chamfer Loss: 8.023598638828844e-05    Cycle Loss: 1.2112693184462842e-05\n",
      "Iteration   56501/ 200000  Loss: 0.00010087005648529157   Chamfer Loss: 7.998197543201968e-05    Cycle Loss: 2.0888079234282486e-05\n",
      "Iteration   57001/ 200000  Loss: 0.00010658569226507097   Chamfer Loss: 8.014336344785988e-05    Cycle Loss: 2.64423324551899e-05\n",
      "Iteration   57501/ 200000  Loss: 0.00010917597683146596   Chamfer Loss: 8.10830169939436e-05    Cycle Loss: 2.8092959837522358e-05\n",
      "Iteration   58001/ 200000  Loss: 0.00010895558079937473   Chamfer Loss: 8.104713924694806e-05    Cycle Loss: 2.790844337141607e-05\n",
      "Iteration   58501/ 200000  Loss: 0.00015481203445233405   Chamfer Loss: 7.948838174343109e-05    Cycle Loss: 7.532365270890296e-05\n",
      "Iteration   59001/ 200000  Loss: 0.00011728800018317997   Chamfer Loss: 8.255599095718935e-05    Cycle Loss: 3.4732005588011816e-05\n",
      "Iteration   59501/ 200000  Loss: 0.00011558608093764633   Chamfer Loss: 8.019917731871828e-05    Cycle Loss: 3.538689998094924e-05\n",
      "Iteration   60001/ 200000  Loss: 9.793275967240334e-05   Chamfer Loss: 7.860964979045093e-05    Cycle Loss: 1.932311170094181e-05\n",
      "Iteration   60501/ 200000  Loss: 0.00012503055040724576   Chamfer Loss: 7.890935376053676e-05    Cycle Loss: 4.612120392266661e-05\n",
      "Iteration   61001/ 200000  Loss: 0.00010175071656703949   Chamfer Loss: 8.209356747101992e-05    Cycle Loss: 1.965715091500897e-05\n",
      "Iteration   61501/ 200000  Loss: 8.58152488945052e-05   Chamfer Loss: 7.889818516559899e-05    Cycle Loss: 6.917060545674758e-06\n",
      "Iteration   62001/ 200000  Loss: 9.203420631820336e-05   Chamfer Loss: 7.779238512739539e-05    Cycle Loss: 1.4241820281313267e-05\n",
      "Iteration   62501/ 200000  Loss: 9.777407831279561e-05   Chamfer Loss: 7.651681517018005e-05    Cycle Loss: 2.1257261323626153e-05\n",
      "Iteration   63001/ 200000  Loss: 0.00011799538333434612   Chamfer Loss: 7.738429849268869e-05    Cycle Loss: 4.061108484165743e-05\n",
      "Iteration   63501/ 200000  Loss: 9.251468145521358e-05   Chamfer Loss: 7.403339259326458e-05    Cycle Loss: 1.84812906809384e-05\n",
      "Iteration   64001/ 200000  Loss: 0.00010675701923901215   Chamfer Loss: 7.667300815228373e-05    Cycle Loss: 3.0084012905717827e-05\n",
      "Iteration   64501/ 200000  Loss: 0.00014645664487034082   Chamfer Loss: 7.860919868107885e-05    Cycle Loss: 6.784745346521959e-05\n",
      "Iteration   65001/ 200000  Loss: 9.68844979070127e-05   Chamfer Loss: 7.587260188302025e-05    Cycle Loss: 2.101189602399245e-05\n",
      "Iteration   65501/ 200000  Loss: 0.0001004527002805844   Chamfer Loss: 7.625214493600652e-05    Cycle Loss: 2.4200557163567282e-05\n",
      "Iteration   66001/ 200000  Loss: 9.047581988852471e-05   Chamfer Loss: 7.388807716779411e-05    Cycle Loss: 1.6587742720730603e-05\n",
      "Iteration   66501/ 200000  Loss: 9.35630378080532e-05   Chamfer Loss: 7.6119220466353e-05    Cycle Loss: 1.7443817341700196e-05\n",
      "Iteration   67001/ 200000  Loss: 0.00011895487841684371   Chamfer Loss: 7.520177314290777e-05    Cycle Loss: 4.375310163595714e-05\n",
      "Iteration   67501/ 200000  Loss: 0.000150423584273085   Chamfer Loss: 7.641909905942157e-05    Cycle Loss: 7.400449248962104e-05\n",
      "Iteration   68001/ 200000  Loss: 8.916923252400011e-05   Chamfer Loss: 7.338603609241545e-05    Cycle Loss: 1.5783200069563463e-05\n",
      "Iteration   68501/ 200000  Loss: 9.696991764940321e-05   Chamfer Loss: 7.391794497380033e-05    Cycle Loss: 2.3051972675602883e-05\n",
      "Iteration   69001/ 200000  Loss: 0.00011733481369446963   Chamfer Loss: 7.366852514678612e-05    Cycle Loss: 4.366628854768351e-05\n",
      "Iteration   69501/ 200000  Loss: 9.19369631446898e-05   Chamfer Loss: 7.267879118444398e-05    Cycle Loss: 1.9258170141256414e-05\n",
      "Iteration   70001/ 200000  Loss: 8.63615277921781e-05   Chamfer Loss: 7.362366886809468e-05    Cycle Loss: 1.273785801458871e-05\n",
      "Iteration   70501/ 200000  Loss: 9.64857536018826e-05   Chamfer Loss: 7.258431287482381e-05    Cycle Loss: 2.39014425460482e-05\n",
      "Iteration   71001/ 200000  Loss: 0.00019097363110631704   Chamfer Loss: 7.385462231468409e-05    Cycle Loss: 0.00011711900151567534\n",
      "Iteration   71501/ 200000  Loss: 8.37980187498033e-05   Chamfer Loss: 7.26265789126046e-05    Cycle Loss: 1.1171436199219897e-05\n",
      "Iteration   72001/ 200000  Loss: 8.735217852517962e-05   Chamfer Loss: 7.13712943252176e-05    Cycle Loss: 1.5980880561983213e-05\n",
      "Iteration   72501/ 200000  Loss: 8.518573304172605e-05   Chamfer Loss: 7.025481318123639e-05    Cycle Loss: 1.4930918041500263e-05\n",
      "Iteration   73001/ 200000  Loss: 7.939135684864596e-05   Chamfer Loss: 6.964804197195917e-05    Cycle Loss: 9.743314876686782e-06\n",
      "Iteration   73501/ 200000  Loss: 9.51422262005508e-05   Chamfer Loss: 7.146671850932762e-05    Cycle Loss: 2.3675507691223174e-05\n",
      "Iteration   74001/ 200000  Loss: 0.00010574977932265028   Chamfer Loss: 7.229090260807425e-05    Cycle Loss: 3.3458876714576036e-05\n",
      "Iteration   74501/ 200000  Loss: 8.966606401372701e-05   Chamfer Loss: 7.027760875644162e-05    Cycle Loss: 1.938845161930658e-05\n",
      "Iteration   75001/ 200000  Loss: 0.0001720954751363024   Chamfer Loss: 7.158476364566013e-05    Cycle Loss: 0.00010051071149064228\n",
      "Iteration   75501/ 200000  Loss: 8.885835995897651e-05   Chamfer Loss: 6.868685159133747e-05    Cycle Loss: 2.0171508367639035e-05\n",
      "Iteration   76001/ 200000  Loss: 8.496873488184065e-05   Chamfer Loss: 6.932288670213893e-05    Cycle Loss: 1.5645846360712312e-05\n",
      "Iteration   76501/ 200000  Loss: 9.443078306503594e-05   Chamfer Loss: 7.00343371136114e-05    Cycle Loss: 2.4396442313445732e-05\n",
      "Iteration   77001/ 200000  Loss: 9.630397835280746e-05   Chamfer Loss: 6.937081343494356e-05    Cycle Loss: 2.693316673685331e-05\n",
      "Iteration   77501/ 200000  Loss: 8.240473107434809e-05   Chamfer Loss: 6.927533104317263e-05    Cycle Loss: 1.3129396393196657e-05\n",
      "Iteration   78001/ 200000  Loss: 7.740587170701474e-05   Chamfer Loss: 6.824201409472153e-05    Cycle Loss: 9.16386125027202e-06\n",
      "Iteration   78501/ 200000  Loss: 7.732619269518182e-05   Chamfer Loss: 6.798304821131751e-05    Cycle Loss: 9.343142664874904e-06\n",
      "Iteration   79001/ 200000  Loss: 7.665967859793454e-05   Chamfer Loss: 6.84437109157443e-05    Cycle Loss: 8.215968591684941e-06\n",
      "Iteration   79501/ 200000  Loss: 8.233292464865372e-05   Chamfer Loss: 6.950158422114328e-05    Cycle Loss: 1.2831342246499844e-05\n",
      "Iteration   80001/ 200000  Loss: 0.00010506460967008024   Chamfer Loss: 6.71212183078751e-05    Cycle Loss: 3.794339136220515e-05\n",
      "Iteration   80501/ 200000  Loss: 7.397059380309656e-05   Chamfer Loss: 6.805604789406061e-05    Cycle Loss: 5.9145472732780036e-06\n",
      "Iteration   81001/ 200000  Loss: 9.995151776820421e-05   Chamfer Loss: 6.843043229309842e-05    Cycle Loss: 3.15210891130846e-05\n",
      "Iteration   81501/ 200000  Loss: 8.910894393920898e-05   Chamfer Loss: 6.635043246205896e-05    Cycle Loss: 2.275851511512883e-05\n",
      "Iteration   82001/ 200000  Loss: 8.063911809585989e-05   Chamfer Loss: 6.821412534918636e-05    Cycle Loss: 1.2424990018189419e-05\n",
      "Iteration   82501/ 200000  Loss: 7.60638722567819e-05   Chamfer Loss: 6.603093061130494e-05    Cycle Loss: 1.0032941645476967e-05\n",
      "Iteration   83001/ 200000  Loss: 0.00017427917919121683   Chamfer Loss: 6.801926792832091e-05    Cycle Loss: 0.00010625991853885353\n",
      "Iteration   83501/ 200000  Loss: 8.827105193631724e-05   Chamfer Loss: 6.659588689217344e-05    Cycle Loss: 2.1675165044143796e-05\n",
      "Iteration   84001/ 200000  Loss: 8.423325925832614e-05   Chamfer Loss: 6.584369111806154e-05    Cycle Loss: 1.8389569959254004e-05\n",
      "Iteration   84501/ 200000  Loss: 7.49173341318965e-05   Chamfer Loss: 6.651314470218495e-05    Cycle Loss: 8.404187610722147e-06\n",
      "Iteration   85001/ 200000  Loss: 7.726056355750188e-05   Chamfer Loss: 6.445175677072257e-05    Cycle Loss: 1.280880496778991e-05\n",
      "Iteration   85501/ 200000  Loss: 7.832572737243026e-05   Chamfer Loss: 6.631550058955327e-05    Cycle Loss: 1.2010226782876998e-05\n",
      "Iteration   86001/ 200000  Loss: 0.00022551347501575947   Chamfer Loss: 6.858123379060999e-05    Cycle Loss: 0.00015693223394919187\n",
      "Iteration   86501/ 200000  Loss: 8.252157567767426e-05   Chamfer Loss: 6.516716530313715e-05    Cycle Loss: 1.7354408555547707e-05\n",
      "Iteration   87001/ 200000  Loss: 8.998399425763637e-05   Chamfer Loss: 6.467210914706811e-05    Cycle Loss: 2.5311885110568255e-05\n",
      "Iteration   87501/ 200000  Loss: 7.452454883605242e-05   Chamfer Loss: 6.546326039824635e-05    Cycle Loss: 9.061284799827263e-06\n",
      "Iteration   88001/ 200000  Loss: 8.057901868596673e-05   Chamfer Loss: 6.567287346115336e-05    Cycle Loss: 1.4906148862792179e-05\n",
      "Iteration   88501/ 200000  Loss: 8.404098480241373e-05   Chamfer Loss: 6.527081859530881e-05    Cycle Loss: 1.877016620710492e-05\n",
      "Iteration   89001/ 200000  Loss: 8.635718404548243e-05   Chamfer Loss: 6.500825111288577e-05    Cycle Loss: 2.1348932932596654e-05\n",
      "Iteration   89501/ 200000  Loss: 8.999135025078431e-05   Chamfer Loss: 6.532137922476977e-05    Cycle Loss: 2.4669971026014537e-05\n",
      "Iteration   90001/ 200000  Loss: 0.00011004383850377053   Chamfer Loss: 6.566871161339805e-05    Cycle Loss: 4.437512325239368e-05\n",
      "Iteration   90501/ 200000  Loss: 7.073209417285398e-05   Chamfer Loss: 6.368476169882342e-05    Cycle Loss: 7.047329745546449e-06\n",
      "Iteration   91001/ 200000  Loss: 0.00010196461516898125   Chamfer Loss: 6.583287176908925e-05    Cycle Loss: 3.613174703787081e-05\n",
      "Iteration   91501/ 200000  Loss: 0.0001061686925822869   Chamfer Loss: 6.454762478824705e-05    Cycle Loss: 4.162106415606104e-05\n",
      "Iteration   92001/ 200000  Loss: 9.415199019713327e-05   Chamfer Loss: 6.436277908505872e-05    Cycle Loss: 2.9789212931063958e-05\n",
      "Iteration   92501/ 200000  Loss: 9.138846507994458e-05   Chamfer Loss: 6.362173007801175e-05    Cycle Loss: 2.7766733182943426e-05\n",
      "Iteration   93001/ 200000  Loss: 7.49838218325749e-05   Chamfer Loss: 6.345983274513856e-05    Cycle Loss: 1.1523991815920454e-05\n",
      "Iteration   93501/ 200000  Loss: 7.092296436894685e-05   Chamfer Loss: 6.58937351545319e-05    Cycle Loss: 5.029229214414954e-06\n",
      "Iteration   94001/ 200000  Loss: 8.245859498856589e-05   Chamfer Loss: 6.39176505501382e-05    Cycle Loss: 1.8540942619438283e-05\n",
      "Iteration   94501/ 200000  Loss: 7.186504080891609e-05   Chamfer Loss: 6.348433817038313e-05    Cycle Loss: 8.380702638532966e-06\n",
      "Iteration   95001/ 200000  Loss: 6.759072130080312e-05   Chamfer Loss: 6.127206142991781e-05    Cycle Loss: 6.318656687653856e-06\n",
      "Iteration   95501/ 200000  Loss: 7.705061580054462e-05   Chamfer Loss: 6.343566928990185e-05    Cycle Loss: 1.3614944691653363e-05\n",
      "Iteration   96001/ 200000  Loss: 9.395067172590643e-05   Chamfer Loss: 6.483474862761796e-05    Cycle Loss: 2.9115926736267284e-05\n",
      "Iteration   96501/ 200000  Loss: 7.514331809943542e-05   Chamfer Loss: 6.257415225263685e-05    Cycle Loss: 1.2569167665787973e-05\n",
      "Iteration   97001/ 200000  Loss: 7.412185368593782e-05   Chamfer Loss: 6.403487350326031e-05    Cycle Loss: 1.0086977454193402e-05\n",
      "Iteration   97501/ 200000  Loss: 7.032575376797467e-05   Chamfer Loss: 6.177854811539873e-05    Cycle Loss: 8.547204743081238e-06\n",
      "Iteration   98001/ 200000  Loss: 7.527560228481889e-05   Chamfer Loss: 6.0884329286636785e-05    Cycle Loss: 1.4391272088687401e-05\n",
      "Iteration   98501/ 200000  Loss: 9.49744280660525e-05   Chamfer Loss: 6.130307883722708e-05    Cycle Loss: 3.367135286680423e-05\n",
      "Iteration   99001/ 200000  Loss: 7.841014303267002e-05   Chamfer Loss: 6.262172246351838e-05    Cycle Loss: 1.578842056915164e-05\n",
      "Iteration   99501/ 200000  Loss: 8.287990203825757e-05   Chamfer Loss: 6.148125976324081e-05    Cycle Loss: 2.1398642275016755e-05\n",
      "Iteration  100001/ 200000  Loss: 6.801920972066e-05   Chamfer Loss: 6.084615961299278e-05    Cycle Loss: 7.173048288677819e-06\n",
      "Iteration  100501/ 200000  Loss: 7.526487752329558e-05   Chamfer Loss: 6.18134654359892e-05    Cycle Loss: 1.3451411177811678e-05\n",
      "Iteration  101001/ 200000  Loss: 8.085522131295875e-05   Chamfer Loss: 6.17072728346102e-05    Cycle Loss: 1.914794665935915e-05\n",
      "Iteration  101501/ 200000  Loss: 7.788780203554779e-05   Chamfer Loss: 6.223029049579054e-05    Cycle Loss: 1.5657507901778445e-05\n",
      "Iteration  102001/ 200000  Loss: 7.451091369148344e-05   Chamfer Loss: 6.0412050515878946e-05    Cycle Loss: 1.4098860447120387e-05\n",
      "Iteration  102501/ 200000  Loss: 8.034896745812148e-05   Chamfer Loss: 6.256316555663943e-05    Cycle Loss: 1.7785805539460853e-05\n",
      "Iteration  103001/ 200000  Loss: 0.00013749883510172367   Chamfer Loss: 6.086736175348051e-05    Cycle Loss: 7.663146971026435e-05\n",
      "Iteration  103501/ 200000  Loss: 7.278130215127021e-05   Chamfer Loss: 5.914433495490812e-05    Cycle Loss: 1.3636969015351497e-05\n",
      "Iteration  104001/ 200000  Loss: 8.340485510416329e-05   Chamfer Loss: 6.088258669478819e-05    Cycle Loss: 2.25222684093751e-05\n",
      "Iteration  104501/ 200000  Loss: 6.56146221444942e-05   Chamfer Loss: 6.117243901826441e-05    Cycle Loss: 4.442183126229793e-06\n",
      "Iteration  105001/ 200000  Loss: 7.30171668692492e-05   Chamfer Loss: 6.07408037467394e-05    Cycle Loss: 1.2276360394025687e-05\n",
      "Iteration  105501/ 200000  Loss: 7.568710861960426e-05   Chamfer Loss: 6.169688276713714e-05    Cycle Loss: 1.3990223123983014e-05\n",
      "Iteration  106001/ 200000  Loss: 0.00012317701475694776   Chamfer Loss: 6.106037471909076e-05    Cycle Loss: 6.211663276189938e-05\n",
      "Iteration  106501/ 200000  Loss: 7.007305248407647e-05   Chamfer Loss: 5.9511665313038975e-05    Cycle Loss: 1.0561387171037495e-05\n",
      "Iteration  107001/ 200000  Loss: 6.967881199670956e-05   Chamfer Loss: 5.851635796716437e-05    Cycle Loss: 1.1162452210555784e-05\n",
      "Iteration  107501/ 200000  Loss: 0.00012815251830033958   Chamfer Loss: 6.077369471313432e-05    Cycle Loss: 6.737883086316288e-05\n",
      "Iteration  108001/ 200000  Loss: 6.6252781834919e-05   Chamfer Loss: 5.8083973272005096e-05    Cycle Loss: 8.168809472408611e-06\n",
      "Iteration  108501/ 200000  Loss: 6.96032220730558e-05   Chamfer Loss: 5.870111272088252e-05    Cycle Loss: 1.0902108442678582e-05\n",
      "Iteration  109001/ 200000  Loss: 8.83805041667074e-05   Chamfer Loss: 5.874406997463666e-05    Cycle Loss: 2.9636432373081334e-05\n",
      "Iteration  109501/ 200000  Loss: 6.446447514463216e-05   Chamfer Loss: 5.917306407354772e-05    Cycle Loss: 5.291411525831791e-06\n",
      "Iteration  110001/ 200000  Loss: 7.087505218805745e-05   Chamfer Loss: 6.0309277614578605e-05    Cycle Loss: 1.0565777301962953e-05\n",
      "Iteration  110501/ 200000  Loss: 8.054902718868107e-05   Chamfer Loss: 5.8513684052741155e-05    Cycle Loss: 2.203534313593991e-05\n",
      "Iteration  111001/ 200000  Loss: 6.636218313360587e-05   Chamfer Loss: 5.866739229531959e-05    Cycle Loss: 7.694789928791579e-06\n",
      "Iteration  111501/ 200000  Loss: 7.02826218912378e-05   Chamfer Loss: 5.675259308191016e-05    Cycle Loss: 1.353003244730644e-05\n",
      "Iteration  112001/ 200000  Loss: 8.511842315783724e-05   Chamfer Loss: 5.898976814933121e-05    Cycle Loss: 2.6128653189516626e-05\n",
      "Iteration  112501/ 200000  Loss: 7.852267299313098e-05   Chamfer Loss: 5.875387432752177e-05    Cycle Loss: 1.9768796846619807e-05\n",
      "Iteration  113001/ 200000  Loss: 6.258822395466268e-05   Chamfer Loss: 5.822409366373904e-05    Cycle Loss: 4.364132109913044e-06\n",
      "Iteration  113501/ 200000  Loss: 7.110172009561211e-05   Chamfer Loss: 5.827215500175953e-05    Cycle Loss: 1.2829567822336685e-05\n",
      "Iteration  114001/ 200000  Loss: 6.325424328679219e-05   Chamfer Loss: 5.759502892033197e-05    Cycle Loss: 5.6592166401969735e-06\n",
      "Iteration  114501/ 200000  Loss: 0.00010453242430230603   Chamfer Loss: 5.85767520533409e-05    Cycle Loss: 4.595567224896513e-05\n",
      "Iteration  115001/ 200000  Loss: 6.669329013675451e-05   Chamfer Loss: 5.7970981288235635e-05    Cycle Loss: 8.722307029529475e-06\n",
      "Iteration  115501/ 200000  Loss: 7.648868631804362e-05   Chamfer Loss: 5.823035826324485e-05    Cycle Loss: 1.8258328054798767e-05\n",
      "Iteration  116001/ 200000  Loss: 6.183805817272514e-05   Chamfer Loss: 5.7482604461256415e-05    Cycle Loss: 4.355455985205481e-06\n",
      "Iteration  116501/ 200000  Loss: 6.769878382328898e-05   Chamfer Loss: 5.701195914298296e-05    Cycle Loss: 1.0686823770811316e-05\n",
      "Iteration  117001/ 200000  Loss: 7.370638923021033e-05   Chamfer Loss: 5.733247962780297e-05    Cycle Loss: 1.6373909602407366e-05\n",
      "Iteration  117501/ 200000  Loss: 7.114098116289824e-05   Chamfer Loss: 5.813856114400551e-05    Cycle Loss: 1.3002421837882139e-05\n",
      "Iteration  118001/ 200000  Loss: 6.630980351474136e-05   Chamfer Loss: 5.69304647797253e-05    Cycle Loss: 9.37933691602666e-06\n",
      "Iteration  118501/ 200000  Loss: 7.66076409490779e-05   Chamfer Loss: 5.752555443905294e-05    Cycle Loss: 1.9082086510024965e-05\n",
      "Iteration  119001/ 200000  Loss: 6.430115172406659e-05   Chamfer Loss: 5.652560867019929e-05    Cycle Loss: 7.775543963361997e-06\n",
      "Iteration  119501/ 200000  Loss: 7.716263644397259e-05   Chamfer Loss: 5.7011500757653266e-05    Cycle Loss: 2.015113568631932e-05\n",
      "Iteration  120001/ 200000  Loss: 6.754898640792817e-05   Chamfer Loss: 5.650608363794163e-05    Cycle Loss: 1.1042904588975944e-05\n",
      "Iteration  120501/ 200000  Loss: 6.342536653392017e-05   Chamfer Loss: 5.816637712996453e-05    Cycle Loss: 5.258989858702989e-06\n",
      "Iteration  121001/ 200000  Loss: 6.662255327682942e-05   Chamfer Loss: 5.699882603948936e-05    Cycle Loss: 9.623729056329466e-06\n",
      "Iteration  121501/ 200000  Loss: 6.493068212876096e-05   Chamfer Loss: 5.5522541515529156e-05    Cycle Loss: 9.408137884747703e-06\n",
      "Iteration  122001/ 200000  Loss: 6.372566713253036e-05   Chamfer Loss: 5.72247154195793e-05    Cycle Loss: 6.5009544414351694e-06\n",
      "Iteration  122501/ 200000  Loss: 6.278986256802455e-05   Chamfer Loss: 5.5780416005291045e-05    Cycle Loss: 7.009444743744098e-06\n",
      "Iteration  123001/ 200000  Loss: 8.086142042884603e-05   Chamfer Loss: 5.5312364565907046e-05    Cycle Loss: 2.554905404394958e-05\n",
      "Iteration  123501/ 200000  Loss: 8.835720655042678e-05   Chamfer Loss: 5.627513746730983e-05    Cycle Loss: 3.2082072721095756e-05\n",
      "Iteration  124001/ 200000  Loss: 6.253702304093167e-05   Chamfer Loss: 5.5985852668527514e-05    Cycle Loss: 6.551170372404158e-06\n",
      "Iteration  124501/ 200000  Loss: 6.317177030723542e-05   Chamfer Loss: 5.573107046075165e-05    Cycle Loss: 7.440698936989065e-06\n",
      "Iteration  125001/ 200000  Loss: 0.0001108591677621007   Chamfer Loss: 5.639472874463536e-05    Cycle Loss: 5.446443901746534e-05\n",
      "Iteration  125501/ 200000  Loss: 6.79082004353404e-05   Chamfer Loss: 5.488311580847949e-05    Cycle Loss: 1.3025081898376811e-05\n",
      "Iteration  126001/ 200000  Loss: 8.348448318429291e-05   Chamfer Loss: 5.591516674030572e-05    Cycle Loss: 2.7569312806008384e-05\n",
      "Iteration  126501/ 200000  Loss: 7.861864287406206e-05   Chamfer Loss: 5.5873169912956655e-05    Cycle Loss: 2.2745471142116003e-05\n",
      "Iteration  127001/ 200000  Loss: 0.00018469351925887167   Chamfer Loss: 5.698132008546963e-05    Cycle Loss: 0.00012771219189744443\n",
      "Iteration  127501/ 200000  Loss: 6.774739449610934e-05   Chamfer Loss: 5.5868516938062385e-05    Cycle Loss: 1.187887664855225e-05\n",
      "Iteration  128001/ 200000  Loss: 6.735682836733758e-05   Chamfer Loss: 5.653442349284887e-05    Cycle Loss: 1.0822405783983413e-05\n",
      "Iteration  128501/ 200000  Loss: 6.647715053986758e-05   Chamfer Loss: 5.533248986466788e-05    Cycle Loss: 1.1144657037220895e-05\n",
      "Iteration  129001/ 200000  Loss: 8.24875314719975e-05   Chamfer Loss: 5.576094190473668e-05    Cycle Loss: 2.672659138625022e-05\n",
      "Iteration  129501/ 200000  Loss: 6.321779073914513e-05   Chamfer Loss: 5.4058902605902404e-05    Cycle Loss: 9.158887223748025e-06\n",
      "Iteration  130001/ 200000  Loss: 5.904062345507555e-05   Chamfer Loss: 5.4069394536782056e-05    Cycle Loss: 4.971228918293491e-06\n",
      "Iteration  130501/ 200000  Loss: 6.996012234594673e-05   Chamfer Loss: 5.400203735916875e-05    Cycle Loss: 1.595808680576738e-05\n",
      "Iteration  131001/ 200000  Loss: 6.05504319537431e-05   Chamfer Loss: 5.504844375536777e-05    Cycle Loss: 5.5019877436279785e-06\n",
      "Iteration  131501/ 200000  Loss: 6.407081673387438e-05   Chamfer Loss: 5.3775034757563844e-05    Cycle Loss: 1.0295779247826431e-05\n",
      "Iteration  132001/ 200000  Loss: 6.623852823395282e-05   Chamfer Loss: 5.4844116675667465e-05    Cycle Loss: 1.1394412467780057e-05\n",
      "Iteration  132501/ 200000  Loss: 6.758314702892676e-05   Chamfer Loss: 5.433777187136002e-05    Cycle Loss: 1.3245372429082636e-05\n",
      "Iteration  133001/ 200000  Loss: 7.152953185141087e-05   Chamfer Loss: 5.529144254978746e-05    Cycle Loss: 1.6238085663644597e-05\n",
      "Iteration  133501/ 200000  Loss: 7.298246055142954e-05   Chamfer Loss: 5.4897216614335775e-05    Cycle Loss: 1.808524211810436e-05\n",
      "Iteration  134001/ 200000  Loss: 6.941644824109972e-05   Chamfer Loss: 5.362638330552727e-05    Cycle Loss: 1.579006675456185e-05\n",
      "Iteration  134501/ 200000  Loss: 5.91378629906103e-05   Chamfer Loss: 5.3718682465841994e-05    Cycle Loss: 5.419179160526255e-06\n",
      "Iteration  135001/ 200000  Loss: 5.98849292146042e-05   Chamfer Loss: 5.449752279673703e-05    Cycle Loss: 5.3874073273618706e-06\n",
      "Iteration  135501/ 200000  Loss: 6.0439157095970586e-05   Chamfer Loss: 5.2987164963269606e-05    Cycle Loss: 7.4519930421956815e-06\n",
      "Iteration  136001/ 200000  Loss: 8.519804396200925e-05   Chamfer Loss: 5.5422122386517e-05    Cycle Loss: 2.977592339448165e-05\n",
      "Iteration  136501/ 200000  Loss: 6.835835665697232e-05   Chamfer Loss: 5.387767305364832e-05    Cycle Loss: 1.4480684512818698e-05\n",
      "Iteration  137001/ 200000  Loss: 6.847475015092641e-05   Chamfer Loss: 5.316673923516646e-05    Cycle Loss: 1.5308007277781144e-05\n",
      "Iteration  137501/ 200000  Loss: 8.382158557651564e-05   Chamfer Loss: 5.4735537560191005e-05    Cycle Loss: 2.9086049835314043e-05\n",
      "Iteration  138001/ 200000  Loss: 5.937412061030045e-05   Chamfer Loss: 5.323885488905944e-05    Cycle Loss: 6.135267085483065e-06\n",
      "Iteration  138501/ 200000  Loss: 9.316329669672996e-05   Chamfer Loss: 5.4296782764140517e-05    Cycle Loss: 3.8866510294610634e-05\n",
      "Iteration  139001/ 200000  Loss: 6.505323108285666e-05   Chamfer Loss: 5.419779699877836e-05    Cycle Loss: 1.0855431355594192e-05\n",
      "Iteration  139501/ 200000  Loss: 6.454139656852931e-05   Chamfer Loss: 5.4189193178899586e-05    Cycle Loss: 1.0352201570640318e-05\n",
      "Iteration  140001/ 200000  Loss: 6.957822915865108e-05   Chamfer Loss: 5.4026553698349744e-05    Cycle Loss: 1.555167546030134e-05\n",
      "Iteration  140501/ 200000  Loss: 5.7062014093389735e-05   Chamfer Loss: 5.232623516349122e-05    Cycle Loss: 4.7357784751511645e-06\n",
      "Iteration  141001/ 200000  Loss: 8.96620549610816e-05   Chamfer Loss: 5.3285955800674856e-05    Cycle Loss: 3.637609916040674e-05\n",
      "Iteration  141501/ 200000  Loss: 7.055909372866154e-05   Chamfer Loss: 5.421422247309238e-05    Cycle Loss: 1.6344873074558564e-05\n",
      "Iteration  142001/ 200000  Loss: 6.845962343504652e-05   Chamfer Loss: 5.329389750841074e-05    Cycle Loss: 1.5165723198151682e-05\n",
      "Iteration  142501/ 200000  Loss: 5.698165114154108e-05   Chamfer Loss: 5.189144576434046e-05    Cycle Loss: 5.090204467705917e-06\n",
      "Iteration  143001/ 200000  Loss: 8.941770647652447e-05   Chamfer Loss: 5.3699317504651845e-05    Cycle Loss: 3.571838897187263e-05\n",
      "Iteration  143501/ 200000  Loss: 5.7180561270797625e-05   Chamfer Loss: 5.2887458878103644e-05    Cycle Loss: 4.293103756936034e-06\n",
      "Iteration  144001/ 200000  Loss: 7.141129754018039e-05   Chamfer Loss: 5.298036921885796e-05    Cycle Loss: 1.8430928321322426e-05\n",
      "Iteration  144501/ 200000  Loss: 9.094394044950604e-05   Chamfer Loss: 5.247046647127718e-05    Cycle Loss: 3.8473477616207674e-05\n",
      "Iteration  145001/ 200000  Loss: 6.68120919726789e-05   Chamfer Loss: 5.3477480832953006e-05    Cycle Loss: 1.3334611139725894e-05\n",
      "Iteration  145501/ 200000  Loss: 6.017274426994845e-05   Chamfer Loss: 5.136133040650748e-05    Cycle Loss: 8.811412044451572e-06\n",
      "Iteration  146001/ 200000  Loss: 5.647104262607172e-05   Chamfer Loss: 5.096221502753906e-05    Cycle Loss: 5.508827598532662e-06\n",
      "Iteration  146501/ 200000  Loss: 5.79784536967054e-05   Chamfer Loss: 5.2661667723441496e-05    Cycle Loss: 5.316787792253308e-06\n",
      "Iteration  147001/ 200000  Loss: 6.07338770350907e-05   Chamfer Loss: 5.1797997002722695e-05    Cycle Loss: 8.935879122873303e-06\n",
      "Iteration  147501/ 200000  Loss: 6.281023524934426e-05   Chamfer Loss: 5.145845716469921e-05    Cycle Loss: 1.1351780813129153e-05\n",
      "Iteration  148001/ 200000  Loss: 6.613842560909688e-05   Chamfer Loss: 5.2268736908445135e-05    Cycle Loss: 1.3869690519641154e-05\n",
      "Iteration  148501/ 200000  Loss: 7.845557411201298e-05   Chamfer Loss: 5.176555714569986e-05    Cycle Loss: 2.669001514732372e-05\n",
      "Iteration  149001/ 200000  Loss: 7.23020129953511e-05   Chamfer Loss: 5.189096918911673e-05    Cycle Loss: 2.0411045625223778e-05\n",
      "Iteration  149501/ 200000  Loss: 5.569258064497262e-05   Chamfer Loss: 5.10069185111206e-05    Cycle Loss: 4.6856639528414235e-06\n",
      "Iteration  150001/ 200000  Loss: 6.129084795247763e-05   Chamfer Loss: 5.1701001211768016e-05    Cycle Loss: 9.589845831214916e-06\n",
      "Iteration  150501/ 200000  Loss: 6.87035862938501e-05   Chamfer Loss: 5.2156079618725926e-05    Cycle Loss: 1.6547508494113572e-05\n",
      "Iteration  151001/ 200000  Loss: 5.869322194484994e-05   Chamfer Loss: 5.149504795554094e-05    Cycle Loss: 7.198173989308998e-06\n",
      "Iteration  151501/ 200000  Loss: 9.284709813073277e-05   Chamfer Loss: 5.2187904657330364e-05    Cycle Loss: 4.0659189835423604e-05\n",
      "Iteration  152001/ 200000  Loss: 6.0475558711914346e-05   Chamfer Loss: 5.0606227887328714e-05    Cycle Loss: 9.869330824585631e-06\n",
      "Iteration  152501/ 200000  Loss: 5.662994954036549e-05   Chamfer Loss: 5.082115239929408e-05    Cycle Loss: 5.808796686324058e-06\n",
      "Iteration  153001/ 200000  Loss: 7.149302837206051e-05   Chamfer Loss: 5.1342194637982175e-05    Cycle Loss: 2.015083191508893e-05\n",
      "Iteration  153501/ 200000  Loss: 5.97501166339498e-05   Chamfer Loss: 5.214592965785414e-05    Cycle Loss: 7.604185611853609e-06\n",
      "Iteration  154001/ 200000  Loss: 5.845436317031272e-05   Chamfer Loss: 5.0415626901667565e-05    Cycle Loss: 8.03873535915045e-06\n",
      "Iteration  154501/ 200000  Loss: 5.91073403484188e-05   Chamfer Loss: 5.074497312307358e-05    Cycle Loss: 8.362367225345224e-06\n",
      "Iteration  155001/ 200000  Loss: 7.772610115353018e-05   Chamfer Loss: 5.16579530085437e-05    Cycle Loss: 2.606814814498648e-05\n",
      "Iteration  155501/ 200000  Loss: 7.269607158377767e-05   Chamfer Loss: 5.0852293497882783e-05    Cycle Loss: 2.184378172387369e-05\n",
      "Iteration  156001/ 200000  Loss: 6.739851232850924e-05   Chamfer Loss: 5.123159644426778e-05    Cycle Loss: 1.6166915884241462e-05\n",
      "Iteration  156501/ 200000  Loss: 6.322333501884714e-05   Chamfer Loss: 5.079984475742094e-05    Cycle Loss: 1.2423488442436792e-05\n",
      "Iteration  157001/ 200000  Loss: 6.265004049055278e-05   Chamfer Loss: 5.033661727793515e-05    Cycle Loss: 1.2313419574638829e-05\n",
      "Iteration  157501/ 200000  Loss: 5.916141526540741e-05   Chamfer Loss: 5.098733527120203e-05    Cycle Loss: 8.174079084710684e-06\n",
      "Iteration  158001/ 200000  Loss: 6.679088983219117e-05   Chamfer Loss: 5.0987327995244414e-05    Cycle Loss: 1.5803561836946756e-05\n",
      "Iteration  158501/ 200000  Loss: 5.8276211348129436e-05   Chamfer Loss: 5.07720178575255e-05    Cycle Loss: 7.5041944000986405e-06\n",
      "Iteration  159001/ 200000  Loss: 5.7201501476811245e-05   Chamfer Loss: 5.095867163618095e-05    Cycle Loss: 6.242829385882942e-06\n",
      "Iteration  159501/ 200000  Loss: 6.6765358496923e-05   Chamfer Loss: 5.008942389395088e-05    Cycle Loss: 1.667593460297212e-05\n",
      "Iteration  160001/ 200000  Loss: 8.330737182404846e-05   Chamfer Loss: 5.176612103241496e-05    Cycle Loss: 3.1541247153654695e-05\n",
      "Iteration  160501/ 200000  Loss: 5.7823261158773676e-05   Chamfer Loss: 5.0736034609144554e-05    Cycle Loss: 7.087227459123824e-06\n",
      "Iteration  161001/ 200000  Loss: 6.476895941887051e-05   Chamfer Loss: 5.0702998123597354e-05    Cycle Loss: 1.4065960385778453e-05\n",
      "Iteration  161501/ 200000  Loss: 5.6963192037073895e-05   Chamfer Loss: 5.092042192700319e-05    Cycle Loss: 6.042770110070705e-06\n",
      "Iteration  162001/ 200000  Loss: 8.566874748794362e-05   Chamfer Loss: 5.109579797135666e-05    Cycle Loss: 3.457294951658696e-05\n",
      "Iteration  162501/ 200000  Loss: 7.607328006997705e-05   Chamfer Loss: 5.057691305410117e-05    Cycle Loss: 2.549636337789707e-05\n",
      "Iteration  163001/ 200000  Loss: 6.195603054948151e-05   Chamfer Loss: 5.012450128560886e-05    Cycle Loss: 1.1831531082862057e-05\n",
      "Iteration  163501/ 200000  Loss: 5.808185233036056e-05   Chamfer Loss: 4.9978723836829886e-05    Cycle Loss: 8.103129403025378e-06\n",
      "Iteration  164001/ 200000  Loss: 5.341200449038297e-05   Chamfer Loss: 4.961637023370713e-05    Cycle Loss: 3.7956349387968658e-06\n",
      "Iteration  164501/ 200000  Loss: 6.035005208104849e-05   Chamfer Loss: 5.051998232374899e-05    Cycle Loss: 9.830071576288901e-06\n",
      "Iteration  165001/ 200000  Loss: 5.7166427723132074e-05   Chamfer Loss: 5.01551476190798e-05    Cycle Loss: 7.011279194557574e-06\n",
      "Iteration  165501/ 200000  Loss: 7.020559860393405e-05   Chamfer Loss: 4.980474477633834e-05    Cycle Loss: 2.0400852008606307e-05\n",
      "Iteration  166001/ 200000  Loss: 6.226431287359446e-05   Chamfer Loss: 4.908965638605878e-05    Cycle Loss: 1.3174660125514492e-05\n",
      "Iteration  166501/ 200000  Loss: 8.170206274371594e-05   Chamfer Loss: 4.977979915565811e-05    Cycle Loss: 3.192226722603664e-05\n",
      "Iteration  167001/ 200000  Loss: 5.766485264757648e-05   Chamfer Loss: 5.001824320061132e-05    Cycle Loss: 7.64661035645986e-06\n",
      "Iteration  167501/ 200000  Loss: 0.00013157149078324437   Chamfer Loss: 5.197315476834774e-05    Cycle Loss: 7.959833601489663e-05\n",
      "Iteration  168001/ 200000  Loss: 6.628957635257393e-05   Chamfer Loss: 5.068935570307076e-05    Cycle Loss: 1.560022064950317e-05\n",
      "Iteration  168501/ 200000  Loss: 0.00010971223673550412   Chamfer Loss: 4.9546513764653355e-05    Cycle Loss: 6.0165722970850766e-05\n",
      "Iteration  169001/ 200000  Loss: 6.421335274353623e-05   Chamfer Loss: 5.0032125727739185e-05    Cycle Loss: 1.4181228834786452e-05\n",
      "Iteration  169501/ 200000  Loss: 5.4594838729826733e-05   Chamfer Loss: 4.918989725410938e-05    Cycle Loss: 5.404940111475298e-06\n",
      "Iteration  170001/ 200000  Loss: 6.891480006743222e-05   Chamfer Loss: 4.936611367156729e-05    Cycle Loss: 1.9548682757886127e-05\n",
      "Iteration  170501/ 200000  Loss: 8.050869655562565e-05   Chamfer Loss: 5.0712467782432213e-05    Cycle Loss: 2.979622695420403e-05\n",
      "Iteration  171001/ 200000  Loss: 0.0001615375222172588   Chamfer Loss: 5.153701931703836e-05    Cycle Loss: 0.00011000051017617807\n",
      "Iteration  171501/ 200000  Loss: 5.844546467415057e-05   Chamfer Loss: 4.854284998145886e-05    Cycle Loss: 9.902615602186415e-06\n",
      "Iteration  172001/ 200000  Loss: 6.124344508862123e-05   Chamfer Loss: 4.930600698571652e-05    Cycle Loss: 1.1937435374420602e-05\n",
      "Iteration  172501/ 200000  Loss: 0.0001024095545290038   Chamfer Loss: 5.108444383949973e-05    Cycle Loss: 5.1325107051525265e-05\n",
      "Iteration  173001/ 200000  Loss: 8.754944428801537e-05   Chamfer Loss: 4.9594924348639324e-05    Cycle Loss: 3.795452357735485e-05\n",
      "Iteration  173501/ 200000  Loss: 5.7854085753206164e-05   Chamfer Loss: 4.784372868016362e-05    Cycle Loss: 1.0010355254053138e-05\n",
      "Iteration  174001/ 200000  Loss: 6.971343100303784e-05   Chamfer Loss: 5.0295453547732905e-05    Cycle Loss: 1.9417977455304936e-05\n",
      "Iteration  174501/ 200000  Loss: 5.435208367998712e-05   Chamfer Loss: 4.9391237553209066e-05    Cycle Loss: 4.960847491020104e-06\n",
      "Iteration  175001/ 200000  Loss: 8.03626753622666e-05   Chamfer Loss: 4.8907430027611554e-05    Cycle Loss: 3.1455245334655046e-05\n",
      "Iteration  175501/ 200000  Loss: 6.75272531225346e-05   Chamfer Loss: 4.9362970457877964e-05    Cycle Loss: 1.816428266465664e-05\n",
      "Iteration  176001/ 200000  Loss: 6.959059101063758e-05   Chamfer Loss: 4.922687367070466e-05    Cycle Loss: 2.036371370195411e-05\n",
      "Iteration  176501/ 200000  Loss: 6.980484613450244e-05   Chamfer Loss: 4.959136276738718e-05    Cycle Loss: 2.0213481548125856e-05\n",
      "Iteration  177001/ 200000  Loss: 5.534803494811058e-05   Chamfer Loss: 4.8705696826800704e-05    Cycle Loss: 6.642339030804578e-06\n",
      "Iteration  177501/ 200000  Loss: 6.51864247629419e-05   Chamfer Loss: 4.852954589296132e-05    Cycle Loss: 1.665688250795938e-05\n",
      "Iteration  178001/ 200000  Loss: 5.817500641569495e-05   Chamfer Loss: 4.9341204430675134e-05    Cycle Loss: 8.833800166030414e-06\n",
      "Iteration  178501/ 200000  Loss: 7.558177458122373e-05   Chamfer Loss: 4.872047793469392e-05    Cycle Loss: 2.6861293008551e-05\n",
      "Iteration  179001/ 200000  Loss: 5.424677146947943e-05   Chamfer Loss: 4.74348125862889e-05    Cycle Loss: 6.8119588831905276e-06\n",
      "Iteration  179501/ 200000  Loss: 5.7871482567861676e-05   Chamfer Loss: 4.818233355763368e-05    Cycle Loss: 9.689149919722695e-06\n",
      "Iteration  180001/ 200000  Loss: 5.89770388614852e-05   Chamfer Loss: 4.789631566382013e-05    Cycle Loss: 1.1080724107159767e-05\n",
      "Iteration  180501/ 200000  Loss: 5.702117414330132e-05   Chamfer Loss: 4.894351150142029e-05    Cycle Loss: 8.077662641881034e-06\n",
      "Iteration  181001/ 200000  Loss: 5.601994052994996e-05   Chamfer Loss: 4.712113150162622e-05    Cycle Loss: 8.898810847313143e-06\n",
      "Iteration  181501/ 200000  Loss: 5.5053704272722825e-05   Chamfer Loss: 4.876098319073208e-05    Cycle Loss: 6.292722446232801e-06\n",
      "Iteration  182001/ 200000  Loss: 5.5041346058715135e-05   Chamfer Loss: 4.885773523710668e-05    Cycle Loss: 6.183610366861103e-06\n",
      "Iteration  182501/ 200000  Loss: 5.24607312399894e-05   Chamfer Loss: 4.800994065590203e-05    Cycle Loss: 4.450792403076775e-06\n",
      "Iteration  183001/ 200000  Loss: 7.593386544613168e-05   Chamfer Loss: 4.848467142437585e-05    Cycle Loss: 2.7449192202766426e-05\n",
      "Iteration  183501/ 200000  Loss: 6.8644032580778e-05   Chamfer Loss: 4.8098532715812325e-05    Cycle Loss: 2.054549622698687e-05\n",
      "Iteration  184001/ 200000  Loss: 6.518339068861678e-05   Chamfer Loss: 4.877184983342886e-05    Cycle Loss: 1.6411540855187923e-05\n",
      "Iteration  184501/ 200000  Loss: 8.907597657525912e-05   Chamfer Loss: 4.796834764420055e-05    Cycle Loss: 4.110762893105857e-05\n",
      "Iteration  185001/ 200000  Loss: 5.314077498042025e-05   Chamfer Loss: 4.817334411200136e-05    Cycle Loss: 4.9674299589241855e-06\n",
      "Iteration  185501/ 200000  Loss: 5.12730039190501e-05   Chamfer Loss: 4.690539208240807e-05    Cycle Loss: 4.367610927147325e-06\n",
      "Iteration  186001/ 200000  Loss: 5.185798363527283e-05   Chamfer Loss: 4.6096578444121405e-05    Cycle Loss: 5.761403826909373e-06\n",
      "Iteration  186501/ 200000  Loss: 0.00011517350503709167   Chamfer Loss: 4.929832721245475e-05    Cycle Loss: 6.587518146261573e-05\n",
      "Iteration  187001/ 200000  Loss: 5.478066668729298e-05   Chamfer Loss: 4.7917801566654816e-05    Cycle Loss: 6.86286421114346e-06\n",
      "Iteration  187501/ 200000  Loss: 5.3909530834062025e-05   Chamfer Loss: 4.801752220373601e-05    Cycle Loss: 5.8920095398207195e-06\n",
      "Iteration  188001/ 200000  Loss: 5.4021587857278064e-05   Chamfer Loss: 4.6411492803599685e-05    Cycle Loss: 7.610094144183677e-06\n",
      "Iteration  188501/ 200000  Loss: 6.379115802701563e-05   Chamfer Loss: 4.810306927538477e-05    Cycle Loss: 1.568809057062026e-05\n",
      "Iteration  189001/ 200000  Loss: 8.635487756691873e-05   Chamfer Loss: 4.812711995327845e-05    Cycle Loss: 3.8227761251619086e-05\n",
      "Iteration  189501/ 200000  Loss: 8.745111699681729e-05   Chamfer Loss: 4.810871905647218e-05    Cycle Loss: 3.934239794034511e-05\n",
      "Iteration  190001/ 200000  Loss: 5.579171920544468e-05   Chamfer Loss: 4.7793277190066874e-05    Cycle Loss: 7.998442015377805e-06\n",
      "Iteration  190501/ 200000  Loss: 5.570968278334476e-05   Chamfer Loss: 4.684081068262458e-05    Cycle Loss: 8.868872100720182e-06\n",
      "Iteration  191001/ 200000  Loss: 6.135395233286545e-05   Chamfer Loss: 4.720852666650899e-05    Cycle Loss: 1.4145427485345863e-05\n",
      "Iteration  191501/ 200000  Loss: 5.348329432308674e-05   Chamfer Loss: 4.711040674010292e-05    Cycle Loss: 6.372888947225874e-06\n",
      "Iteration  192001/ 200000  Loss: 5.272313501336612e-05   Chamfer Loss: 4.677437027567066e-05    Cycle Loss: 5.948766101937508e-06\n",
      "Iteration  192501/ 200000  Loss: 5.81887288717553e-05   Chamfer Loss: 4.7065150283742696e-05    Cycle Loss: 1.1123579497507308e-05\n",
      "Iteration  193001/ 200000  Loss: 5.2555154979927465e-05   Chamfer Loss: 4.6791617933195084e-05    Cycle Loss: 5.763537956227083e-06\n",
      "Iteration  193501/ 200000  Loss: 5.160262662684545e-05   Chamfer Loss: 4.643675492843613e-05    Cycle Loss: 5.165872607904021e-06\n",
      "Iteration  194001/ 200000  Loss: 5.7629786169854924e-05   Chamfer Loss: 4.607060327543877e-05    Cycle Loss: 1.1559181984921452e-05\n",
      "Iteration  194501/ 200000  Loss: 7.371664833044633e-05   Chamfer Loss: 4.7395100409630686e-05    Cycle Loss: 2.6321547920815647e-05\n",
      "Iteration  195001/ 200000  Loss: 6.778548413421959e-05   Chamfer Loss: 4.699885903391987e-05    Cycle Loss: 2.0786628738278523e-05\n",
      "Iteration  195501/ 200000  Loss: 7.640221156179905e-05   Chamfer Loss: 4.689669731305912e-05    Cycle Loss: 2.9505514248739928e-05\n",
      "Iteration  196001/ 200000  Loss: 5.147731280885637e-05   Chamfer Loss: 4.557305874186568e-05    Cycle Loss: 5.904252248001285e-06\n",
      "Iteration  196501/ 200000  Loss: 5.959135160082951e-05   Chamfer Loss: 4.738206189358607e-05    Cycle Loss: 1.220928879774874e-05\n",
      "Iteration  197001/ 200000  Loss: 7.36167494324036e-05   Chamfer Loss: 4.83809199067764e-05    Cycle Loss: 2.5235829525627196e-05\n",
      "Iteration  197501/ 200000  Loss: 5.116702595842071e-05   Chamfer Loss: 4.585204806062393e-05    Cycle Loss: 5.314976988302078e-06\n",
      "Iteration  198001/ 200000  Loss: 6.514243432320654e-05   Chamfer Loss: 4.6605618990724906e-05    Cycle Loss: 1.853681715147104e-05\n",
      "Iteration  198501/ 200000  Loss: 5.912902270210907e-05   Chamfer Loss: 4.681852078647353e-05    Cycle Loss: 1.2310500096646138e-05\n",
      "Iteration  199001/ 200000  Loss: 6.47275082883425e-05   Chamfer Loss: 4.618538514478132e-05    Cycle Loss: 1.8542123143561184e-05\n",
      "Iteration  199501/ 200000  Loss: 5.4589596402365714e-05   Chamfer Loss: 4.589983291225508e-05    Cycle Loss: 8.689762580615934e-06\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "\n",
    "# Pretraining\n",
    "for i in range(iterations):\n",
    "    output = model(None, init_pass=True)\n",
    "\n",
    "    sampled_uv_points, points3d, inverted_uv_points = output[\"sampled_uv_points\"], output[\"points3d\"], output[\"inverted_uv_points\"]\n",
    "\n",
    "    # Chamfer Loss\n",
    "    chamfer_loss, _ = chamfer_distance(mesh_vertices.unsqueeze(0), points3d.unsqueeze(0), point_reduction=\"mean\")\n",
    "    # 2D-3D-2D Cycle Loss\n",
    "    cycle_loss = ((sampled_uv_points - inverted_uv_points)**2).sum(axis=-1).mean()\n",
    "    \n",
    "    loss = chamfer_loss + cycle_loss\n",
    "    \n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    loss_history.append(loss.item())\n",
    "    if i % print_every_iter == 0:\n",
    "        print(f\"Iteration {i+1:7d}/{iterations:7d}  Loss: {loss_history[-1]}   Chamfer Loss: {chamfer_loss.item()}    Cycle Loss: {cycle_loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af7a3d4a-2e0a-4d2d-8cd1-8e400c97fc44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.semilogy(loss_history[100:], label=\"Train Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c08a2401-198b-4297-85b6-53b193c13464",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Make some visualizations\n",
    "model.eval()\n",
    "\n",
    "# Collect some random points\n",
    "output = model(None, init_pass=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6d9a19d-b355-4c6e-a652-db1c275f0dd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53054f85eeb14fcc81779841955df26d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ViewInteractiveWidget(height=768, layout=Layout(height='auto', width='100%'), width=1024)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize 3D Points\n",
    "predicted = output[\"points3d\"]\n",
    "gt = mesh_vertices\n",
    "\n",
    "plotter = pv.Plotter()\n",
    "\n",
    "predicted = pv.PolyData(predicted.cpu().detach().numpy())\n",
    "plotter.add_mesh(predicted, color=\"yellow\", render_points_as_spheres=True)\n",
    "\n",
    "gt = pv.PolyData(mesh_vertices.cpu().detach().numpy())\n",
    "plotter.add_mesh(gt, color=\"black\", render_points_as_spheres=True)\n",
    "\n",
    "plotter.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14f39f76-56a0-47cf-895e-c59be183fc3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12c3d9b8871845df839d50aab6355466",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ViewInteractiveWidget(height=768, layout=Layout(height='auto', width='100%'), width=1024)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize Sphere Mapping\n",
    "sampled_uv = output[\"sampled_uv_points\"]\n",
    "inverted_uv = output[\"inverted_uv_points\"]\n",
    "\n",
    "plotter = pv.Plotter()\n",
    "\n",
    "sampled = pv.PolyData(sampled_uv.cpu().detach().numpy())\n",
    "plotter.add_mesh(sampled, color=\"yellow\", point_size=5., render_points_as_spheres=True)\n",
    "\n",
    "inverted = pv.PolyData(inverted_uv.cpu().detach().numpy())\n",
    "plotter.add_mesh(inverted, color=\"black\", point_size=5., render_points_as_spheres=True)\n",
    "\n",
    "plotter.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cbe171dd-68ec-41b4-aeeb-307a2ecca885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the weights\n",
    "\n",
    "# out_dir = \"neutex/pretrained/cat_rescaled_rotated_pretrained_neutex_mapping.pt\"\n",
    "out_dir = \"neutex/pretrained/human_pretrained_neutex_mapping.pt\"\n",
    "\n",
    "assert not os.path.exists(out_dir)\n",
    "torch.save({\n",
    "    \"net_inverse_atlasnet_3d_to_uv\": model.net_inverse_atlasnet_3d_to_uv.state_dict(),\n",
    "    \"net_atlasnet_uv_to_3d\": model.net_atlasnet_uv_to_3d.state_dict()\n",
    "}, out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58d7dd9-b919-4e56-951e-1c7c0fa6c513",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
